
@misc{superdata,
	title = {Superconductivty Data Data Set },
	url = {https://archive.ics.uci.edu/ml/datasets/Superconductivty+Data},
	urldate = {2018-10-12}
}


@article{hamidieh,
	title = {A {Data}-{Driven} {Statistical} {Model} for {Predicting} the {Critical} {Temperature} of a {Superconductor}},
	url = {http://arxiv.org/abs/1803.10260},
	language = {en},
	urldate = {2021-05-25},
	journal = {arXiv:1803.10260 [stat]},
	author = {Hamidieh, Kam},
	month = oct,
	year = {2018},
	note = {arXiv: 1803.10260},
	keywords = {Statistics - Applications},
	file = {Hamidieh - 2018 - A Data-Driven Statistical Model for Predicting the.pdf:/home/fjaviersaezm/Zotero/storage/UZTRJ5WJ/Hamidieh - 2018 - A Data-Driven Statistical Model for Predicting the.pdf:application/pdf},
}




@misc{noauthor_uci_nodate,
	title = {{UCI} {Machine} {Learning} {Repository}: {Dataset} for {Sensorless} {Drive} {Diagnosis} {Data} {Set}},
	url = {https://archive.ics.uci.edu/ml/datasets/dataset+for+sensorless+drive+diagnosis},
	urldate = {2021-05-31},
	file = {UCI Machine Learning Repository\: Dataset for Sensorless Drive Diagnosis Data Set:/home/fjaviersaezm/Zotero/storage/A6R23TWX/dataset+for+sensorless+drive+diagnosis.html:text/html},
}


@misc{noauthor_hilberthuang_2021,
	title = {Hilbert–{Huang} transform},
	copyright = {Creative Commons Attribution-ShareAlike License},
	url = {https://en.wikipedia.org/w/index.php?title=Hilbert%E2%80%93Huang_transform&oldid=1021767752},
	abstract = {The Hilbert–Huang transform (HHT) is a way to decompose a signal into so-called intrinsic mode functions (IMF) along with a trend, and obtain instantaneous frequency data.  It is designed to work well for data that is nonstationary and nonlinear.  In contrast to other common transforms like the Fourier transform, the HHT is more like an algorithm (an empirical approach) that can be applied to a data set, rather than a theoretical tool.},
	language = {en},
	urldate = {2021-05-31},
	journal = {Wikipedia},
	month = may,
	year = {2021},
	note = {Page Version ID: 1021767752},
	file = {Snapshot:/home/fjaviersaezm/Zotero/storage/Q5BEMSCA/index.html:text/html},
}


@electronic{2013applied,
  added-at = {2015-05-25T13:54:39.000+0200},
  address = {New York, NY},
  author = {Kuhn, Max and Johnson, Kjell},
  biburl = {https://www.bibsonomy.org/bibtex/20ffe1d130cc2d823a0d83058c337dd8d/vivion},
  booktitle = {Applied Predictive Modeling},
  description = {Applied Predictive Modeling: 9781461468486: Medicine & Health Science Books @ Amazon.com},
  interhash = {28fb1de6e768ed47c29f0a5d6d6dbe5d},
  intrahash = {0ffe1d130cc2d823a0d83058c337dd8d},
  isbn = {9781461468493 1461468493 1461468485 9781461468486},
  keywords = {ML data-science machine-learning statistics},
  publisher = {Springer},
  refid = {844349710},
  timestamp = {2015-05-25T14:06:06.000+0200},
  title = {Applied predictive modeling},
  url = {http://www.amazon.com/Applied-Predictive-Modeling-Max-Kuhn/dp/1461468485/},
  year = 2013
}

@book{learn_from_data,
author = {Abu-Mostafa, Yaser S. and Magdon-Ismail, Malik and Lin, Hsuan-Tien},
title = {Learning From Data},
year = {2012},
isbn = {1600490069},
publisher = {AMLBook}
}


@article{wattenberg_how_2016,
	title = {How to {Use} t-{SNE} {Effectively}},
	volume = {1},
	issn = {2476-0757},
	url = {http://distill.pub/2016/misread-tsne},
	doi = {10.23915/distill.00002},
	abstract = {Although extremely useful for visualizing high-dimensional data, t-SNE plots can sometimes be mysterious or misleading.},
	language = {en},
	number = {10},
	urldate = {2021-06-02},
	journal = {Distill},
	author = {Wattenberg, Martin and Viégas, Fernanda and Johnson, Ian},
	month = oct,
	year = {2016},
	pages = {e2},
	file = {Snapshot:/home/fjaviersaezm/Zotero/storage/JXG7W6I4/misread-tsne.html:text/html},
}


@article{van_der_maaten_viualizing_2008,
	title = {Viualizing data using t-{SNE}},
	volume = {9},
	abstract = {We present a new technique called "t-SNE" that visualizes high-dimensional data by giving each datapoint a location in a two or three-dimensional map. The technique is a variation of Stochastic Neighbor Embedding (Hinton and Roweis, 2002) that is much easier to optimize, and produces significantly better visualizations by reducing the tendency to crowd points together in the center of the map. t-SNE is better than existing techniques at creating a single map that reveals structure at many different scales. This is particularly important for high-dimensional data that lie on several different, but related, low-dimensional manifolds, such as images of objects from multiple classes seen from multiple viewpoints. For visualizing the structure of very large data sets, we show how t-SNE can use random walks on neighborhood graphs to allow the implicit structure of all of the data to influence the way in which a subset of the data is displayed. We illustrate the performance of t-SNE on a wide variety of data sets and compare it with many other non-parametric visualization techniques, including Sammon mapping, Isomap, and Locally Linear Embedding. The visualiza-tions produced by t-SNE are significantly better than those produced by the other techniques on almost all of the data sets.},
	journal = {Journal of Machine Learning Research},
	author = {van der Maaten, Laurens and Hinton, Geoffrey},
	month = nov,
	year = {2008},
	pages = {2579--2605},
	file = {Full Text PDF:/home/fjaviersaezm/Zotero/storage/UA9VZQNE/van der Maaten and Hinton - 2008 - Viualizing data using t-SNE.pdf:application/pdf},
}


@misc{saez_fjsaezmml_2021,
	title = {fjsaezm/{ML}},
	url = {https://github.com/fjsaezm/ML/blob/75278b9a95ccb579cfe48c3ef87328296db8faf4/P2/memoria.pdf},
	abstract = {Repo for the work done in the subject: Machine Learning at Universidad de Granada.},
	urldate = {2021-06-03},
	author = {Sáez, Javier},
	month = jun,
	year = {2021},
	note = {original-date: 2021-03-03T09:34:26Z},
}